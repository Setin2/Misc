{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPngZLKgOMC7DQcJx06rFzq"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "from gym import wrappers\n",
        "import random\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "from collections import defaultdict\n",
        "import itertools\n",
        "import ast"
      ],
      "metadata": {
        "id": "IW5oOsj3MQL9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 304,
      "metadata": {
        "id": "dEJnGTQVCJiQ"
      },
      "outputs": [],
      "source": [
        "class TicTacToe:\n",
        "    def __init__(self):\n",
        "        self.board = []\n",
        "        self.previous_board = []\n",
        "        self.moves = [[0, 0], [0, 1], [0, 2], [1, 0], [1, 1], [1, 2], [2, 0], [2, 1], [2, 2]]\n",
        "\n",
        "    def reset(self):\n",
        "      self.board = []\n",
        "      for i in range(3):\n",
        "          row = []\n",
        "          for j in range(3):\n",
        "              row.append(-1)\n",
        "          self.board.append(row)\n",
        "      return self.board\n",
        "\n",
        "    def step(self, move, player):\n",
        "      move = self.moves[move]\n",
        "      row, col = move[0], move[1]\n",
        "      if self.board[row][col] == -1:\n",
        "        self.previous_board = copy.deepcopy(self.board)\n",
        "        self.board[row][col] = player\n",
        "        # done and this player won, +1 reward\n",
        "        if self.done(player):\n",
        "          return self.board, 1, True\n",
        "        # done and its a draw, -1 reward\n",
        "        elif self.is_board_filled():\n",
        "          return self.board, -1, True\n",
        "        # not done, 0 reward\n",
        "        else: return self.board, 0, False\n",
        "      #else: print(self.board, move)\n",
        "\n",
        "    def done(self, player):\n",
        "        win = None\n",
        "\n",
        "        n = len(self.board)\n",
        "\n",
        "        # checking rows\n",
        "        for i in range(n):\n",
        "            win = True\n",
        "            for j in range(n):\n",
        "                if self.board[i][j] != player:\n",
        "                    win = False\n",
        "                    break\n",
        "            if win:\n",
        "                return win\n",
        "\n",
        "        # checking columns\n",
        "        for i in range(n):\n",
        "            win = True\n",
        "            for j in range(n):\n",
        "                if self.board[j][i] != player:\n",
        "                    win = False\n",
        "                    break\n",
        "            if win:\n",
        "                return win\n",
        "\n",
        "        # checking diagonals\n",
        "        win = True\n",
        "        for i in range(n):\n",
        "            if self.board[i][i] != player:\n",
        "                win = False\n",
        "                break\n",
        "        if win:\n",
        "            return win\n",
        "\n",
        "        win = True\n",
        "        for i in range(n):\n",
        "            if self.board[i][n - 1 - i] != player:\n",
        "                win = False\n",
        "                break\n",
        "        if win:\n",
        "            return win\n",
        "        return False\n",
        "\n",
        "        for row in self.board:\n",
        "            for item in row:\n",
        "                if item == -1:\n",
        "                    return False\n",
        "        return True\n",
        "\n",
        "    # we check if the other player has won (which means that this one lost)\n",
        "    def player_lost(self, player):\n",
        "      player = 1 if player == 0 else 1\n",
        "      return self.done(player)\n",
        "\n",
        "    def is_board_filled(self):\n",
        "        for row in self.board:\n",
        "            for item in row:\n",
        "                if item == -1:\n",
        "                    return False\n",
        "        return True\n",
        "\n",
        "    def get_possible_moves(self, state):\n",
        "        moves = []\n",
        "        for index in range(len(self.moves)):\n",
        "          move = self.moves[index]\n",
        "          if state[move[0]][move[1]] == -1:\n",
        "            moves.append(self.moves.index(move))\n",
        "        return moves\n",
        "    \n",
        "    def undo(self):\n",
        "        self.board = self.previous_board\n",
        "\n",
        "    def render(self):\n",
        "        for row in self.board:\n",
        "            for item in row:\n",
        "                print(item, end=\" \")\n",
        "            print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class N_Step_Q_Learning():\n",
        "  def __init__(self, env, N, epsilon, learning_rate=0.9, discount_factor=0.95, initial_q_value=0.5):\n",
        "        self.env = env\n",
        "        self.player = 0\n",
        "        self.Q = {}  # [string, np.ndarray]\n",
        "        self.states = []\n",
        "        self.actions = []\n",
        "        self.rewards = []\n",
        "        self.discount_factor = discount_factor\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epsilon = epsilon\n",
        "        self.initial_q_value = initial_q_value\n",
        "        self.N = N\n",
        "        super().__init__()\n",
        "\n",
        "  \"\"\"\n",
        "    We get the q-values of all the actions given this state\n",
        "    If the state is not in the Q-table, we initialize all the q-values as initial_q_value\n",
        "  \"\"\"\n",
        "  def get_q_value(self, hashed_state):\n",
        "      if hashed_state in self.Q:\n",
        "        return self.Q[hashed_state]\n",
        "      else: \n",
        "        q_values = np.full(9, self.initial_q_value)\n",
        "        self.Q[hashed_state] = q_values\n",
        "        return q_values\n",
        "\n",
        "  \"\"\"\n",
        "    We get the action that has the best q-value\n",
        "  \"\"\"\n",
        "  def get_action(self, state):\n",
        "      q_values = self.get_q_value(str(state))\n",
        "\n",
        "      posible_actions = self.env.get_possible_moves(state)\n",
        "      best_possible_action = posible_actions[0]\n",
        "      for action in posible_actions:\n",
        "        if q_values[action] > best_possible_action:\n",
        "          best_possible_action = action\n",
        "      return best_possible_action\n",
        "\n",
        "  \"\"\"\n",
        "    Randomly select an action from the list of possible actions, or get an action based on learned policy depending on our sample\n",
        "    If the current state hasnt been visited before, we initialize the q-values for all actions as initial_q_value\n",
        "  \"\"\"\n",
        "  def random_epsilon_greedy_policy(self, state):\n",
        "    sample = random.random()\n",
        "    if sample > self.epsilon:\n",
        "      return self.get_action(state)\n",
        "    else:\n",
        "      actions = self.env.get_possible_moves(state)\n",
        "      hashed_state = str(state)\n",
        "      if hashed_state in self.Q:\n",
        "        return actions[random.randrange(len(actions))]\n",
        "      else: \n",
        "        q_values = np.full(9, self.initial_q_value)\n",
        "        self.Q[hashed_state] = q_values\n",
        "        return actions[random.randrange(len(actions))]\n",
        "\n",
        "  # https://rl-book.com/learn/value_methods/n_step/\n",
        "  # https://medium.com/zero-equals-false/n-step-td-method-157d3875b9cb\n",
        "  def train(self, state):\n",
        "    t = 0           # current timestep\n",
        "    t_update = 0    # timestep at which we update the q-value\n",
        "    while True:\n",
        "      t += 1\n",
        "      # policy takes an action first\n",
        "      action = self.random_epsilon_greedy_policy(state)\n",
        "      self.states.append(str(state))\n",
        "      self.actions.append(action)\n",
        "      # we observe the next state and reward\n",
        "      next_state, reward, done = self.env.step(action, self.player)\n",
        "      state = next_state\n",
        "      self.player = 1\n",
        "\n",
        "      # this player has not won yet, so expert also takes an action\n",
        "      if not done:\n",
        "        action = self.expert_policy(state, self.player)\n",
        "        # we observe the next state and reward again\n",
        "        next_state, reward, done = self.env.step(action, self.player)\n",
        "        state = next_state\n",
        "        self.player = 0\n",
        "      \n",
        "      # the player must have lost the game, we penalize it\n",
        "      if done and self.player == 0:\n",
        "        reward = -2\n",
        "      \n",
        "      # we can finally save the reward as well\n",
        "      self.rewards.append(reward)\n",
        "\n",
        "      # we reached the number of steps needed to update our policy\n",
        "      if t >= self.N:\n",
        "          # we compute the discounted reward for n steps\n",
        "          G = 0\n",
        "          for i in range(t_update, t):\n",
        "            G += self.discount_factor**(i - t_update - 1) * self.rewards[i]\n",
        "\n",
        "          # we have yet to visit the next state, so we initialize all its q-values as initial_q_value\n",
        "          if not str(next_state) in self.Q:\n",
        "            self.Q[str(next_state)] = np.full(9, self.initial_q_value)\n",
        "          # we compute the estimated value after n\n",
        "          G += self.discount_factor**self.N * self.Q[str(next_state)]\n",
        "\n",
        "          # improve policy according to the bellman update\n",
        "          self.Q[self.states[t_update]][self.actions[t_update]] += self.learning_rate * (np.max(G) - self.Q[self.states[t_update]][self.actions[t_update]]) \n",
        "\n",
        "          t_update += 1\n",
        "\n",
        "      if done:\n",
        "        #self.env.render()\n",
        "        #print()\n",
        "        self.reset()\n",
        "        return reward\n",
        "  \n",
        "  def reset(self):\n",
        "    self.player = 0\n",
        "    self.states = []\n",
        "    self.actions = []\n",
        "    self.rewards = []\n",
        "  \n",
        "  \"\"\"\n",
        "    We use the minmax algorithm to get the score of each action and return the action with max score\n",
        "  \"\"\"\n",
        "  def expert_policy(self, state, player):\n",
        "    bestScore = -math.inf\n",
        "    best_action = None\n",
        "    env_clone = copy.deepcopy(self.env)\n",
        "    for action in env_clone.get_possible_moves(state):\n",
        "        env_clone.step(action, player)\n",
        "        score = self.minimax(False, player, env_clone)\n",
        "        env_clone.undo()\n",
        "        if (score > bestScore):\n",
        "            bestScore = score\n",
        "            best_action = action\n",
        "    return best_action\n",
        "\n",
        "  \"\"\"\n",
        "    In short this algorithm makes a search tree for the given state and returns a score\n",
        "  \"\"\"\n",
        "  def minimax(self, isMaxTurn, player, env_copy):\n",
        "      state = env_copy.board\n",
        "      # draw\n",
        "      if (env_copy.is_board_filled()):\n",
        "          return -1\n",
        "      # this player won\n",
        "      elif (env_copy.done(player)):\n",
        "          return 1\n",
        "      # this player lost\n",
        "      elif (env_copy.player_lost(player)):\n",
        "          print(\"lost\")\n",
        "          return -2\n",
        "\n",
        "      scores = []\n",
        "      for action in env_copy.get_possible_moves(state):\n",
        "          env_copy.step(action, player)\n",
        "          scores.append(self.minimax(not isMaxTurn, player, env_copy))\n",
        "          env_copy.undo()\n",
        "\n",
        "      return max(scores) if isMaxTurn else min(scores)"
      ],
      "metadata": {
        "id": "8Wz1RmPtNcrV"
      },
      "execution_count": 321,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = TicTacToe()\n",
        "agent = N_Step_Q_Learning(env, N=3, epsilon=0.1, initial_q_value=0.5)"
      ],
      "metadata": {
        "id": "6gZF3Snljh93"
      },
      "execution_count": 377,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPISODES = 100\n",
        "\n",
        "rew = []\n",
        "\n",
        "for e in range(EPISODES):\n",
        "  state = env.reset()\n",
        "  reward = agent.train(state)\n",
        "  if e % 5 == 0:\n",
        "    rew.append(reward)\n",
        "\n",
        "ln = list(range(0, int(EPISODES / 5)))\n",
        "ln = [i * 5 for i in ln]\n",
        "plt.figure(1, figsize=(8, 6))\n",
        "plt.plot(ln, rew)\n",
        "plt.xlabel('episode')\n",
        "plt.ylabel('rewards')\n",
        "#print(agent.Q['[[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]'])\n",
        "#print(agent.Q)"
      ],
      "metadata": {
        "id": "jXfw9e8nMxQQ",
        "outputId": "91c0d07f-a81c-48d6-fd07-61cc40ab3e2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        }
      },
      "execution_count": 385,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'rewards')"
            ]
          },
          "metadata": {},
          "execution_count": 385
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}